{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My GPU: <pyopencl.Device 'Cayman' on 'AMD Accelerated Parallel Processing' at 0x6262f20>\n",
      "My CPU: <pyopencl.Device 'Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz' on 'AMD Accelerated Parallel Processing' at 0x670ddc0>\n",
      "Vector A:\n",
      "[  0.   5.  10.  15.  20.  25.  30.  35.  40.  45.  50.] \n",
      "Vector B:\n",
      "[  0.   5.  10.  15.  20.  25.  30.  35.  40.  45.  50.] \n",
      "Results:\n",
      "[   0.   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.]\n",
      "[   0.   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.]\n",
      "[   0.   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.]\n",
      "\n",
      "Time taken for python vector_add:\n",
      " 1.99757185079 seconds\n",
      "Time taken for OpenCL vector_add on: Cayman \n",
      " 0.0502282665568 seconds\n",
      "Time taken for OpenCL vector_add on: Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz \n",
      " 0.0373442226314 seconds\n"
     ]
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Get opencl devices:\n",
    "plat = cl.get_platforms()\n",
    "devices = plat[0].get_devices()\n",
    "print \"My GPU:\",devices[0]\n",
    "print \"My CPU:\",devices[1]\n",
    "\n",
    "# Create contexts for my devices\n",
    "#ctx_gpu = cl.Context([devices[0]])\n",
    "#ctx_cpu = cl.Context([devices[1]])\n",
    "\n",
    "#print ctx_gpu\n",
    "#print ctx_cpu\n",
    "\n",
    "# OpenCL vector addition function\n",
    "def opencl_vectorAdd(a, b, ctx):\n",
    "\n",
    "    queue = cl.CommandQueue(ctx) # create a queue to schedule the kernel to run on the device\n",
    "\n",
    "    # Create memory buffers\n",
    "    mf = cl.mem_flags\n",
    "    a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "    b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "    dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, b.nbytes)\n",
    "\n",
    "    # OpenCL code \n",
    "    prg = cl.Program(ctx, \"\"\"\n",
    "        __kernel void vectorAdd(__global float *output,\n",
    "                                __global const float *in_A,\n",
    "                                __global const float *in_B)\n",
    "        {\n",
    "            int id = get_global_id(0);        // get global thread ID\n",
    "            output[id] = in_A[id] + in_B[id]; // perform vector adition\n",
    "        }\n",
    "        \"\"\").build()\n",
    "\n",
    "    result = np.empty_like(a) # place to store the result\n",
    "    prg.vectorAdd(queue, a.shape, None, dest_buf, a_buf, b_buf).wait() # do the vector add\n",
    "    cl.enqueue_copy(queue, result, dest_buf) # copy the results from buffer into result\n",
    "    #print \"\\nresult\",result    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Python vector addition function\n",
    "def py_vectorAdd(vec_a, vec_b):\n",
    "    vec_c = np.zeros(len(vec_a))\n",
    "    if len(vec_a) != len(vec_b):\n",
    "        print \"Vector A is not the same size as vector B.\"\n",
    "        print \"Vector A has length\", len(vec_a),\n",
    "        print \"while vector B has length\", len(vec_b)\n",
    "    else:\n",
    "        for i in range(len(vec_c)):\n",
    "            vec_c[i] = vec_a[i] + vec_b[i]\n",
    "    return vec_c\n",
    "\n",
    "\n",
    "# Test \n",
    "a = np.arange(0,55,5).astype(np.float32)\n",
    "b = np.arange(0,55,5).astype(np.float32)\n",
    "print \"Vector A:\\n\", a, \"\\nVector B:\\n\", b, \"\\nResults:\"\n",
    "print py_vectorAdd(a,b)\n",
    "print opencl_vectorAdd(a, b, cl.Context([devices[0]]))\n",
    "print opencl_vectorAdd(a, b, cl.Context([devices[1]]))\n",
    "\n",
    "\n",
    "\n",
    "# Execution time comparisons:\n",
    "\n",
    "ex_time = np.zeros(3)\n",
    "\n",
    "sz = 5000000\n",
    "a = np.random.rand(sz).astype(np.float32)\n",
    "b = np.random.rand(sz).astype(np.float32)\n",
    "\n",
    "start = cv2.getTickCount()\n",
    "py_vectorAdd(a,b)\n",
    "end = cv2.getTickCount()\n",
    "ex_time[0] = (end - start)/ cv2.getTickFrequency()\n",
    "\n",
    "print \"\\nTime taken for python vector_add:\\n {0} seconds\".format(ex_time[0])\n",
    "\n",
    "#start = time.time()\n",
    "#opencl_vectorAdd(a, b, ctx=ctx_gpu)\n",
    "#end = time.time()\n",
    "#print \"Time taken for OpenCL GPU vector_add: {0} seconds\".format(end - start)\n",
    "\n",
    "#start = time.time()\n",
    "#opencl_vectorAdd(a, b, ctx=ctx_cpu)\n",
    "#end = time.time()\n",
    "#print \"Time taken for OpenCL CPU vector_add: {0} seconds\".format(end - start)\n",
    "\n",
    "\n",
    "for dev in range(len(devices)):\n",
    "    start = cv2.getTickCount()\n",
    "    opencl_vectorAdd(a, b, cl.Context([devices[dev]]))\n",
    "    end = cv2.getTickCount()\n",
    "    ex_time[dev+1] = (end - start)/ cv2.getTickFrequency()\n",
    "    print \"Time taken for OpenCL vector_add on:\", str(devices[dev]).split('\\'')[1], \"\\n {0} seconds\".format(ex_time[dev+1])\n",
    "\n",
    "sz = np.arange(10,200000,10000)\n",
    "#sz = [1,10, 100, 1000, 10000, 100000,1000000, 10000000, 50000000, 80000000 ]\n",
    "dev_names = ['Python CPU', 'OpenCL GPU', 'OpenCL CPU']\n",
    "py_exec_time = np.zeros(len(sz))\n",
    "cpu_exec_time = np.zeros(len(sz))\n",
    "gpu_exec_time = np.zeros(len(sz))\n",
    "   \n",
    "a = np.random.rand(max(sz)).astype(np.float32)\n",
    "b = np.random.rand(max(sz)).astype(np.float32)\n",
    "\n",
    "for i in range(len(sz)):\n",
    "    start = cv2.getTickCount()\n",
    "    py_vectorAdd(a[:sz[i]],b[:sz[i]])\n",
    "    end = cv2.getTickCount()\n",
    "    py_exec_time[i] = (end - start)/ cv2.getTickFrequency()\n",
    "    \n",
    "#print py_exec_time\n",
    "\n",
    "for i in range(len(sz)):\n",
    "    start = cv2.getTickCount()\n",
    "    opencl_vectorAdd(a[:sz[i]],b[:sz[i]], cl.Context([devices[0]]))\n",
    "    end = cv2.getTickCount()\n",
    "    gpu_exec_time[i] = (end - start)/ cv2.getTickFrequency()\n",
    "    \n",
    "#print gpu_exec_time\n",
    "\n",
    "for i in range(len(sz)):\n",
    "    start = cv2.getTickCount()\n",
    "    opencl_vectorAdd(a[:sz[i]],b[:sz[i]], cl.Context([devices[1]]))\n",
    "    end = cv2.getTickCount()\n",
    "    cpu_exec_time[i] = (end - start)/ cv2.getTickFrequency()\n",
    "\n",
    "#print cpu_exec_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
