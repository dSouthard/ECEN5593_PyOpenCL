{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__kernel void Reduce(\n",
    "__global float *g_in,\n",
    "    __global float *g_out,\n",
    "    unsigned int n,\n",
    "    __local float *sdata)\n",
    "\n",
    "C code:\n",
    "{\n",
    "    // load shared mem\n",
    "    unsigned int tid = get_local_id(0);\n",
    "    unsigned int i = get_global_id(0);\n",
    "\n",
    "    sdata[tid] = (i < n) ? g_idata[i] : 0;\n",
    "\n",
    "    barrier(CLK_LOCAL_MEM_FENCE);\n",
    "\n",
    "    // do reduction in shared mem\n",
    "    for(unsigned int s=1; s < get_local_size(0); s *= 2) {\n",
    "        // modulo arithmetic is slow!\n",
    "        if ((tid % (2*s)) == 0) {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "\n",
    "    // write result for this block to global mem\n",
    "    if (tid == 0) g_odata[get_group_id(0)] = sdata[0];\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Matrix multiplication: OpenCL kernel improved\n",
    "\n",
    "__kernel void mmul(\n",
    "    const int Mdim,\n",
    "    const int Ndim,\n",
    "    const int Pdim,\n",
    "    __global float *A,\n",
    "    __global float *B,\n",
    "    __global float *C)\n",
    "\n",
    "\n",
    "C code:\n",
    "{\n",
    "  int k;\n",
    "  int i = get_global_id(0);\n",
    "  int j = get_global_id(1);\n",
    "  float tmp = 0.0f;\n",
    "  for (k = 0; k < Pdim; k++) \n",
    "    tmp += A[i*Ndim+k] * B[k*Pdim+j];\n",
    "  }\n",
    "  C[i*Ndim+j] += tmp;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13048ddfe4be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_some_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cl' is not defined"
     ]
    }
   ],
   "source": [
    "ctx = cl.create_some_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.nehalemlabs.net/prototype/blog/2014/04/28/parallel-programming-with-opencl-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(32).astype(np.float32)\n",
    "res = np.empty_like(a)\n",
    "\n",
    "ctx = cl.create_some_context()   # create the context\n",
    "queue = cl.CommandQueue(ctx)    # create a queue\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, res.nbytes)\n",
    "\n",
    "# This is the actual opencl code\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "    __kernel void sq(__global const float *a,\n",
    "    __global float *c)\n",
    "    {\n",
    "      int gid = get_global_id(0);\n",
    "      c[gid] = a[gid] * a[gid];\n",
    "    }\n",
    "    \"\"\").build()\n",
    "\n",
    "prg.sq(queue, a.shape, None, a_buf, dest_buf,)\n",
    "\n",
    "cl.enqueue_copy(queue, res, dest_buf)\n",
    "\n",
    "print a, res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of test without OpenCL:  0.431999921799 s\n",
      "===============================================================\n",
      "Platform name: AMD Accelerated Parallel Processing\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Advanced Micro Devices, Inc.\n",
      "Platform version: OpenCL 2.0 AMD-APP (1800.11)\n",
      "---------------------------------------------------------------\n",
      "Device name: Cayman\n",
      "Device type: GPU\n",
      "Device memory:  2048 MB\n",
      "Device max clock speed: 880 MHz\n",
      "Device compute units: 24\n",
      "Device max work group size: 256\n",
      "Device max work item sizes: [256L, 256L, 256L]\n",
      "(64,)\n",
      "Data points: 67108864\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 64\n",
      "Execution time of test: 0.00596478 s\n",
      "Results do not match!!\n",
      "===============================================================\n",
      "Platform name: AMD Accelerated Parallel Processing\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: Advanced Micro Devices, Inc.\n",
      "Platform version: OpenCL 2.0 AMD-APP (1800.11)\n",
      "---------------------------------------------------------------\n",
      "Device name: Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz\n",
      "Device type: CPU\n",
      "Device memory:  6135 MB\n",
      "Device max clock speed: 3192 MHz\n",
      "Device compute units: 8\n",
      "Device max work group size: 1024\n",
      "Device max work item sizes: [1024L, 1024L, 1024L]\n",
      "(64,)\n",
      "Data points: 67108864\n",
      "Workers: 64\n",
      "Preferred work group size multiple: 1\n",
      "Execution time of test: 0.178914 s\n",
      "Results do not match!!\n"
     ]
    }
   ],
   "source": [
    "# example provided by Roger Pau Monn'e\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import pyopencl as cl\n",
    "import numpy\n",
    "import numpy.linalg as la\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "data_points = 2**26 # ~8 million data points, ~32 MB data\n",
    "workers = 2**6 # 256 workers, play with this to see performance differences\n",
    "               # eg: 2**0 => 1 worker will be non-parallel execution on gpu\n",
    "               # data points must be a multiple of workers\n",
    "\n",
    "a = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "b = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "c_result = numpy.empty_like(a)\n",
    "\n",
    "# Speed in normal CPU usage\n",
    "time1 = time()\n",
    "c_temp = (a+b) # adds each element in a to its corresponding element in b\n",
    "c_temp = c_temp * c_temp # element-wise multiplication\n",
    "c_result = c_temp * (a/2.0) # element-wise half a and multiply\n",
    "time2 = time()\n",
    "\n",
    "print(\"Execution time of test without OpenCL: \", time2 - time1, \"s\")\n",
    "\n",
    "\n",
    "for platform in cl.get_platforms():\n",
    "    for device in platform.get_devices():\n",
    "        print(\"===============================================================\")\n",
    "        print(\"Platform name:\", platform.name)\n",
    "        print(\"Platform profile:\", platform.profile)\n",
    "        print(\"Platform vendor:\", platform.vendor)\n",
    "        print(\"Platform version:\", platform.version)\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(\"Device name:\", device.name)\n",
    "        print(\"Device type:\", cl.device_type.to_string(device.type))\n",
    "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
    "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
    "        print(\"Device compute units:\", device.max_compute_units)\n",
    "        print(\"Device max work group size:\", device.max_work_group_size)\n",
    "        print(\"Device max work item sizes:\", device.max_work_item_sizes)\n",
    "\n",
    "        # Simnple speed test\n",
    "        ctx = cl.Context([device])\n",
    "        queue = cl.CommandQueue(ctx, \n",
    "                properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "        mf = cl.mem_flags\n",
    "        a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "        b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "        dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, b.nbytes)\n",
    "\n",
    "        prg = cl.Program(ctx, \"\"\"\n",
    "            __kernel void sum(__global const float *a,\n",
    "            __global const float *b, __global float *c)\n",
    "            {\n",
    "                        int gid = get_global_id(0);\n",
    "                        float a_temp;\n",
    "                        float b_temp;\n",
    "                        float c_temp;\n",
    "                        a_temp = a[gid]; // my a element (by global ref)\n",
    "                        b_temp = b[gid]; // my b element (by global ref)\n",
    "                        \n",
    "                        c_temp = a_temp+b_temp; // sum of my elements\n",
    "                        c_temp = c_temp * c_temp; // product of sums\n",
    "                        c_temp = c_temp * (a_temp/2.0); // times 1/2 my a\n",
    "                        c[gid] = c_temp; // store result in global memory\n",
    "                }\n",
    "                \"\"\").build()\n",
    "\n",
    "        global_size=(data_points,)\n",
    "        local_size=(workers,)\n",
    "        preferred_multiple = cl.Kernel(prg, 'sum').get_work_group_info( \\\n",
    "            cl.kernel_work_group_info.PREFERRED_WORK_GROUP_SIZE_MULTIPLE, \\\n",
    "            device)\n",
    "\n",
    "        print(\"Data points:\", data_points)\n",
    "        print(\"Workers:\", workers)\n",
    "        print(\"Preferred work group size multiple:\", preferred_multiple)\n",
    "\n",
    "        if (workers % preferred_multiple):\n",
    "            print(\"Number of workers not a preferred multiple (%d*N).\" \\\n",
    "                    % (preferred_multiple))\n",
    "            print(\"Performance may be reduced.\")\n",
    "\n",
    "        exec_evt = prg.sum(queue, global_size, local_size, a_buf, b_buf, dest_buf)\n",
    "        exec_evt.wait()\n",
    "        elapsed = 1e-9*(exec_evt.profile.end - exec_evt.profile.start)\n",
    "\n",
    "        print(\"Execution time of test: %g s\" % elapsed)\n",
    "\n",
    "        c = numpy.empty_like(a)\n",
    "        cl.enqueue_copy(queue, dest_buf, c).wait()\n",
    "        equal = numpy.all( c == c_result)\n",
    "\n",
    "        if not equal:\n",
    "                print(\"Results do not match!!\")\n",
    "        else:\n",
    "                print(\"Results OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "sz = [10000, 100000, 1000000, 10000000, 100000000]\n",
    "exec_time = dict()\n",
    "for i in range(len(sz)):\n",
    "    exec_time[i] = np.zeros(3)\n",
    "    a = np.random.rand(sz[i]).astype(np.float32)\n",
    "    b = np.random.rand(sz[i]).astype(np.float32)\n",
    "\n",
    "    start = time.time()\n",
    "    py_vectorAdd(a,b)\n",
    "    end = time.time()\n",
    "    ex_time[i][0] = end - start\n",
    "\n",
    "    for dev in range(len(devices)):\n",
    "        start = time.time()\n",
    "        opencl_vectorAdd(a, b, cl.Context([devices[dev]]))\n",
    "        end = time.time()\n",
    "        ex_time[i][dev+1] = end - start\n",
    "        #print \"Time taken for OpenCL vector_add on:\", str(devices[dev]).split('\\'')[1], \"\\n {0} seconds\".format(ex_time[dev+1])\n",
    "\n",
    "    # Plot the data:\n",
    "    names = ['Python', 'OpenCL GPU', 'OpenCL CPU']\n",
    "    ax = plt.subplot(121)\n",
    "    plt.xlabel('Device')\n",
    "    plt.ylabel('Execution time (s)')\n",
    "    plt.title('Execution time for Vector Add')\n",
    "    plt.grid(True)\n",
    "    bins = map(lambda x: x-0.5/2,range(1,len(ex_time)+1))\n",
    "    ax.bar(bins,ex_time,0.5)\n",
    "    ax.set_xticks(map(lambda x: x, range(1,len(ex_time)+1)))\n",
    "    ax.set_xticklabels(names,rotation=45, rotation_mode=\"anchor\", ha=\"right\")\n",
    "    #plt.show()\n",
    "\n",
    "    # Plot the data to compare CPU to GPU:\n",
    "\n",
    "    ax = plt.subplot(122)\n",
    "    plt.xlabel('Device')\n",
    "    #plt.ylabel('Execution time (s)')\n",
    "    plt.title('(GPU vs CPU)')\n",
    "    plt.grid(True)\n",
    "    bins = map(lambda x: x-0.5/2,range(1,len(ex_time[1:3])+1))\n",
    "    ax.bar(bins,ex_time[1:3],0.5)\n",
    "    ax.set_xticks(map(lambda x: x, range(1,len(ex_time[1:3])+1)))\n",
    "    ax.set_xticklabels(names[1:3],rotation=45, rotation_mode=\"anchor\", ha=\"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(10)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x, x)\n",
    "plt.plot(x, 2 * x)\n",
    "plt.plot(x, 3 * x)\n",
    "plt.plot(x, 4 * x)\n",
    "\n",
    "plt.legend(['y = x', 'y = 2x', 'y = 3x', 'y = 4x'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
